{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-24T08:24:40.071427Z",
     "start_time": "2024-07-24T08:24:38.502863Z"
    }
   },
   "source": [
    "from src.model_training.datasets.experiments_sanitize.no_sanitization import DefinitionDataset as OrigDataset\n",
    "from src.model_training.datasets.experiments_sanitize.mixed_sanitization import DefinitionDataset\n",
    "from src.model_training.datasets.experiments_sanitize.complete_sanitization import DefinitionDataset as CleanedDataset\n",
    "from src.model_training.datasets.experiments_sanitize.complete_sanitization import DefinitionTestSet as CleanedTestDataset\n",
    "from src.model_training.training.experiments_adapters.double_seq_bn import DefinitionModel\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "import regex as re\n",
    "import pandas as pd\n",
    "import pandasgui\n",
    "\n",
    "old_special_idx = []\n"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T08:24:44.510445Z",
     "start_time": "2024-07-24T08:24:43.984120Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('bert-base-cased')\n",
    "set_train_unsanitized, set_val_unsanitized = OrigDataset.create_dataset(tokenizer=tokenizer, shuffle=True, seed=42)"
   ],
   "id": "4f0d224c0c91157f",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-18T14:22:03.414809Z",
     "start_time": "2024-07-18T14:21:53.042804Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for x in set_train_unsanitized:\n",
    "    if \"{{übertr.:}}\" in x[\"context_sentence\"]:\n",
    "        print(x)\n",
    "        break"
   ],
   "id": "82886951a47482bb",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T08:23:17.245890Z",
     "start_time": "2024-07-24T08:22:02.392030Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer, _ = DefinitionModel.create_model()\n",
    "set_test = CleanedTestDataset.create_dataset(tokenizer=tokenizer, shuffle=True, seed=42)"
   ],
   "id": "72f16bd662259109",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generating test split: 0 examples [00:00, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f6c470a1ef5347c79d337e106bce43e1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Flattening the indices:   0%|          | 0/35738 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "1f63c744d26a464faa1b3926cda45f3d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Tokenizer not available, using no tokenizer\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/35738 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bd89aadc7ed4d09853e6b4bf0d81ba1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/35726 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "20f2325eb50943d68b523445fb3adbfc"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b6e91ac5dd7f4e94a23f361321796252"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Filter:   0%|          | 0/35722 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "065b6102c3e54094a8ddf3671f19e07d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T14:40:51.944176Z",
     "start_time": "2024-07-17T14:40:51.944112Z"
    }
   },
   "cell_type": "code",
   "source": [
    "tokenizer, _ = DefinitionModel.create_model()\n",
    "set_train_unsanitized, set_val_unsanitized = OrigDataset.create_dataset(tokenizer=tokenizer, shuffle=True, seed=42)\n",
    "set_train_sanitized, set_val_sanitized = CleanedDataset.create_dataset(tokenizer=tokenizer, shuffle=True, seed=42)\n",
    "\n",
    "old_special_idx = []"
   ],
   "id": "68a3c93261c5b105",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T09:01:43.855062Z",
     "start_time": "2024-07-16T09:01:43.851376Z"
    }
   },
   "cell_type": "code",
   "source": "set_test[4]",
   "id": "20600951e669a554",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'title': 'Freilichtbühne',\n",
       " 'context_word': 'Freilichtbühne',\n",
       " 'context_sentence': '\"Sie steht auf der großen Freilichtbühne und schaut etwas ungläubig.\"',\n",
       " 'gt': 'Bühne unter freiem Himmel',\n",
       " 'input_ids': [313,\n",
       "  78295,\n",
       "  259,\n",
       "  13009,\n",
       "  1015,\n",
       "  442,\n",
       "  9063,\n",
       "  278,\n",
       "  20757,\n",
       "  38066,\n",
       "  316,\n",
       "  126123,\n",
       "  472,\n",
       "  259,\n",
       "  36499,\n",
       "  270,\n",
       "  259,\n",
       "  14427,\n",
       "  263,\n",
       "  259,\n",
       "  1485,\n",
       "  183123,\n",
       "  12670,\n",
       "  2454,\n",
       "  7702,\n",
       "  856,\n",
       "  398,\n",
       "  76360,\n",
       "  795,\n",
       "  20757,\n",
       "  38066,\n",
       "  316,\n",
       "  126123,\n",
       "  291,\n",
       "  1],\n",
       " 'attention_mask': [1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1],\n",
       " 'labels': [364, 126123, 4880, 22724, 470, 105849, 1],\n",
       " 'prompt': '\"Sie steht auf der großen Freilichtbühne und schaut etwas ungläubig.\" Was ist die Definition von Freilichtbühne? '}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T08:48:30.311075Z",
     "start_time": "2024-07-24T08:43:33.924878Z"
    }
   },
   "cell_type": "code",
   "source": [
    "debug_me = []\n",
    "\n",
    "def global_sanitize(input_text):\n",
    "    input_text = re.sub(r\"<small>\\[[0-9]*\\]<\\/small>\", \"\", input_text)\n",
    "    input_text = re.sub(r\"<sup>.*?<\\/sup>\", \"\", input_text)\n",
    "    input_text = re.sub(r\"\\(\\[http:.*?''Internet-Beleg''\\)\", \"\", input_text)\n",
    "    input_text = re.sub(r\"<!?--.*?-->\", \"\", input_text)\n",
    "    input_text = re.sub(r\"<\\/?span.*?>\", \"\", input_text)\n",
    "    input_text = re.sub(r\"\\u200b\", \"\", input_text)\n",
    "    input_text = re.sub(r\"(\\u200b|\\u200e|\\u2060|\\u200d|\\u200c)\", \"\", input_text)\n",
    "    \n",
    "    def remove_tags(input_text, tag):\n",
    "        return input_text.replace(f\"<{tag}>\", \"\").replace(f\"</{tag}>\", \"\")\n",
    "\n",
    "    input_text = remove_tags(input_text, \"small\")\n",
    "    input_text = remove_tags(input_text, \"big\")\n",
    "    input_text = remove_tags(input_text, \"sub\")\n",
    "    input_text = remove_tags(input_text, \"code\")\n",
    "    input_text = remove_tags(input_text, \"u\")\n",
    "    input_text = remove_tags(input_text, \"s\")\n",
    "    input_text = remove_tags(input_text, \"small cap\")\n",
    "    \n",
    "    regex = re.compile(r'<(ref|REF).*?</(ref|REF)>')\n",
    "    input_text = regex.sub('', input_text)\n",
    "    regex = re.compile(r'<(ref|REF).*?(ref|REF)>')\n",
    "    input_text = regex.sub('', input_text)\n",
    "    regex = re.compile(r'<(ref|REF).*?/>')\n",
    "    input_text = regex.sub('', input_text)\n",
    "    regex = re.compile(r'<div.*?</div>')\n",
    "    input_text = regex.sub('', input_text)\n",
    "\n",
    "    input_text = re.sub(r'\\[\\[([^\\|\\]]+)\\]\\]', r'\\1', input_text)\n",
    "    \n",
    "    replacements_k = {\n",
    "        \"ugs.\": \"umgangssprachlich\",\n",
    "        \"refl.\": \"\", # \"reflexiv\",\n",
    "        \"trans.\": \"\", # \"transitiv\",\n",
    "        \"abw.\": \"abwertend\",\n",
    "        \"übertr.\": \"übertragen\",\n",
    "        \"va.\": \"vor allem\",\n",
    "        \"sal.\": \"salopp\",\n",
    "        \"allg.\": \"allgemein\",\n",
    "        \"auch\": \"\",\n",
    "        \"kein Plural\": \"\"\n",
    "    }\n",
    "    \n",
    "    replacements_old = {\n",
    "        \"{{trans.|:}}\": \"\",\n",
    "        \"{{trans.|,}}\": \"\",\n",
    "        '{{gM}}': \"\",\n",
    "        '{{übertr.|:}}': \"übertragen:\",\n",
    "        '{{ugs.|,}}': \"umgangssprachlich,\",\n",
    "        \"{{ugs.|:}}\": \"umgangssprachlich:\",\n",
    "        \"{{ugs.}}\": \"umgangssprachlich\",\n",
    "        '{{QS Bedeutungen}}': \"\",\n",
    "        '{{scherzh.|:}}': \"scherzhaft:\",\n",
    "        '{{scherzh.}}': \"scherzhaft:\",\n",
    "        '{{geh.|:}}': \"gehoben:\",\n",
    "        '{{intrans.|:}}': \"\",\n",
    "        '{{refl.|:}}': \"\",\n",
    "        '{{kPl.|:}}': \"\",\n",
    "        '{{kPl.}}': \"\",\n",
    "        '{{fachspr.}}': \"fachsprachlich\",\n",
    "        '{{schweiz.|:}}': \"schweizerisch:\",\n",
    "        '{{österr.}}': \"östereichisch:\",\n",
    "        '{{veraltend|:}}': \"veraltend:\",\n",
    "        '{{refl.|,}}': \"\",\n",
    "        '{{trans.}}': \"\",\n",
    "        '{{NNBSP}}': \" \",\n",
    "        '{{QS Bedeutungen|unbelegt|spr=de}}': \"\",\n",
    "        '{{QS Bedeutungen|unbelegt}}': \"\",\n",
    "        '{{intrans.|,}}': \"\",\n",
    "        '{{va.}}': \"vor allem.\",\n",
    "        '{{intrans.|;}}': \"\",\n",
    "        '{{abw.|:}}': \"abwertend:\",\n",
    "        '{{abw.}}': \"abwertend\",\n",
    "        '{{va.|:}}': \"vor allem:\",\n",
    "        '{{trans.|;}}': \"\",\n",
    "        '{{intrans.}}': \"\",\n",
    "        '{{ugs.|}}': \"umgangssprachlich\",\n",
    "        '{{vul.|:}}': \"vulgär:\",\n",
    "        '{{QS Bedeutungen|stilistisch und semantisch seltsam}}': \"\",\n",
    "        '{{refl.}}': \"\",\n",
    "        '{{landsch.|:}}': \"landschaftlich:\",\n",
    "        '{{geh.|,}}': \"gehoben,\",\n",
    "        '{{QS Bedeutungen|keine Synonymauflistung, siehe Hilfe:Bedeutungen}}': \"\",\n",
    "        '{{QS Bedeutungen|fehlend}}': \"\",\n",
    "        '{{schweiz.|,}}': \"schweizerisch,\",\n",
    "        '{{österr.|,}}': \"östereichisch,\",\n",
    "        '{{österr.|:}}': \"östereichisch:\",\n",
    "        '{{österr.|}}': \"östereichisch\",\n",
    "        '{{QS Herkunft|fehlt}}': \"\",\n",
    "        '₂': \"2\",\n",
    "        '¹': \"\",\n",
    "        '<!--erweitern-->': \"\",\n",
    "        '²': \"2\",\n",
    "        '³': \"3\",\n",
    "        '⁴': \"4\",\n",
    "        '×': \"x\",\n",
    "        '−': \"-\",\n",
    "        '_': \"_\",\n",
    "        '′': \"'\",\n",
    "        '½': \"1/2\",\n",
    "        '‐': \"-\",\n",
    "        '‑': \"-\",\n",
    "        '̩': \"\",\n",
    "        '±': \"+-\",\n",
    "        '₃': \"3\",\n",
    "        '″': \"\\\"\",\n",
    "        '”': \"\\\"\",\n",
    "        '`': \"'\",\n",
    "        '‟': \"\\\"\",\n",
    "        '⁻': \"-\",\n",
    "        '₅': \"5\",\n",
    "        '⁄': \"/\",\n",
    "        '⅓': \"1/3\",\n",
    "        '(¨)': \"\",\n",
    "        '‛': \"'\",\n",
    "        '©': \"\",\n",
    "        '⁶': \"6\",\n",
    "        '·': \"x\",\n",
    "        \"„\": \"\\\"\", \n",
    "        \"“\": \"\\\"\", \n",
    "        \"»\": \"\\\"\", \n",
    "        \"«\": \"\\\"\", \n",
    "        \"›\": \"\\\"\", \n",
    "        \"‹\": \"\\\"\", \n",
    "        \"‚\": \"\\\"\", \n",
    "        \"‘\": \"\\\"\", \n",
    "        \"´\": \"\\\"\", \n",
    "        \"’\": \"'\", \n",
    "        \"…\": \"...\", \n",
    "        \"–\": \"-\", \n",
    "        \"—\": \"-\", \n",
    "        \"®\": \"\",\n",
    "        \"''\": \"\",\n",
    "        \"<br>\": \" \",\n",
    "        \"</br>\": \" \",\n",
    "        \"<br/>\": \" \",\n",
    "        \"<br />\": \" \",\n",
    "        \"{{(R)}}\": \"\",\n",
    "        \"&#91;sic&#93;\": \"[sic]\",\n",
    "        \"&#8239;\": \" \",\n",
    "        \"&#x202f;\": \" \",\n",
    "        \"<nowiki>[</nowiki>\": \"\",\n",
    "        \"<nowiki>]</nowiki>\": \"\",\n",
    "        \"<!--\": \"\",\n",
    "        \"□\": \"\",\n",
    "        \"{{Neutr.}}\": \"\",\n",
    "        \"\\x93\": \"\", \n",
    "        \"\\x96\": \"\",\n",
    "        \"\\x84\": \"\",\n",
    "        \"\\x80\": \"\",\n",
    "        '{{Beispiele fehlen}}': \"\",\n",
    "        '{{CH&LI}}': \"\",\n",
    "        '{{CURRENTYEAR}}': \"\",\n",
    "        '{{Herkunft}}': \"\",\n",
    "        '{{IPA}}': \"\",\n",
    "        '{{Mask.}}': \"\",\n",
    "        '{{Pl.}}': \"\",\n",
    "        '{{es.}}': \"\",\n",
    "        '{{fam.|:}}': \"familiär:\",\n",
    "        '{{fam.|;}}': \"familiär;\",\n",
    "        '{{gM|r}}': \"\",\n",
    "        '{{hist.|:}}': \"historisch\",\n",
    "        '{{kPl.|,}}': \"\",\n",
    "        '{{kSt.}}': \"\",\n",
    "        '{{landsch.|}}': \"landschaftlich\",\n",
    "        '{{landsch.}}': \"landschaftlich\",\n",
    "        '{{m}}': \"m\",\n",
    "        '{{nordd.}}': \"norddeutsch\",\n",
    "        '{{n}}': \"n\",\n",
    "        '{{reg.}}': \"\",\n",
    "        '{{scherzh.|,}}': \"scherzhaft,\",\n",
    "        '{{schweiz.}}': \"schweizerisch\",\n",
    "        '{{südd.|:}}': \"süddeutsch:\",\n",
    "        '{{südd.|,}}': \"süddeutsch,\",\n",
    "        '{{ugs.|;}}': \"umgangssprachlich;\",\n",
    "        '{{va.|,}}': \"vor allem,\",\n",
    "        '{{veraltet|:}}': \"veraltet:\",\n",
    "        '{{vergleiche}}': \"vergleiche\",\n",
    "        '{{übertr.:}}': \"übertragen:\",\n",
    "        '{{übertr.}}': \"übertragen\",\n",
    "        '{{übertr.|;}}': \"übertragen;\",\n",
    "        \"{{fig.|:}}\": \"figurativ:\",\n",
    "        '{{md.}}': \"\",\n",
    "        '{{f}}': \"\",\n",
    "        \"→\": \"\",\n",
    "        \"vatd.\": \"veraltend\",\n",
    "        \"landsch.\": \"landschaftlich\",\n",
    "        \"|sonst|\": \"|\",\n",
    "    }\n",
    "    replacements = {\n",
    "                '_': \"_\",\n",
    "        '‐': \"-\",\n",
    "        '‑': \"-\",\n",
    "        '·': \"x\",\n",
    "        '̩': \"\",\n",
    "        '‛': \"'\",\n",
    "        '”': \"\\\"\",\n",
    "        '‟': \"\\\"\",\n",
    "        '(¨)': \"\",\n",
    "        'abw.': \"abwertend\",\n",
    "        '{{Beispiele fehlen}}': \"\",\n",
    "        'CH&LI': \"\",\n",
    "        'CURRENTYEAR': \"\",\n",
    "        '{{es.}}': \"\",\n",
    "        '{{f}}': \"\",\n",
    "        '{{fachspr.}}': \"fachsprachlich\",\n",
    "        'fam.': \"familiär;\",\n",
    "        '{{gM}}': \"\",\n",
    "        '{{gM|r}}': \"\",\n",
    "        '{{Herkunft}}': \"\",\n",
    "        'hist.': \"historisch\",\n",
    "        'intrans.': \"\",\n",
    "        '{{IPA}}': \"\",\n",
    "        'kPl.': \"\",\n",
    "        'kSt.': \"\",\n",
    "        'geh.': \"gehoben\",\n",
    "        'landsch.': \"landschaftlich\",\n",
    "        '{{m}}': \"m\",\n",
    "        '{{Mask.}}': \"\",\n",
    "        '{{md.}}': \"\",\n",
    "        '{{n}}': \"n\",\n",
    "        'NNBSP': \" \",\n",
    "        'nordd.': \"norddeutsch\",\n",
    "        'österr.': \"östereichisch:\",\n",
    "        'Pl.': \"\",\n",
    "        'QS Bedeutungen': \"\",\n",
    "        'QS Herkunft': \"\",\n",
    "        'refl.': \"\",\n",
    "        'reg.': \"\",\n",
    "        'scherzh.': \"scherzhaft\",\n",
    "        'schweiz.': \"schweizerisch\",\n",
    "        'südd.': \"süddeutsch,\",\n",
    "        'trans.': \"\",\n",
    "        'übertr.': \"übertragen:\",\n",
    "        'ugs.': \"umgangssprachlich,\",\n",
    "        'va.': \"vor allem.\",\n",
    "        '{{vergleiche}}': \"vergleiche\",\n",
    "        'vul.': \"vulgär:\",\n",
    "        '′': \"'\",\n",
    "        '″': \"\\\"\",\n",
    "        '`': \"'\",\n",
    "        '©': \"\",\n",
    "        '±': \"+-\",\n",
    "        '×': \"x\",\n",
    "        '<!--erweitern-->': \"\",\n",
    "        '−': \"-\",\n",
    "        '⁻': \"-\",\n",
    "        '⁄': \"/\",\n",
    "        '¹': \"\",\n",
    "        '½': \"1/2\",\n",
    "        '⅓': \"1/3\",\n",
    "        '²': \"2\",\n",
    "        '₂': \"2\",\n",
    "        '³': \"3\",\n",
    "        '₃': \"3\",\n",
    "        '⁴': \"4\",\n",
    "        '₅': \"5\",\n",
    "        '⁶': \"6\",\n",
    "        \"–\": \"-\", \n",
    "        \"—\": \"-\", \n",
    "        \"…\": \"...\", \n",
    "        \"''\": \"\",\n",
    "        \"’\": \"'\", \n",
    "        \" ́\": \"'\",\n",
    "        \"‘\": \"\\\"\", \n",
    "        \"‚\": \"\\\"\", \n",
    "        \"‹\": \"\\\"\", \n",
    "        \"›\": \"\\\"\", \n",
    "        \"“\": \"\\\"\", \n",
    "        \"„\": \"\\\"\", \n",
    "        \"«\": \"\\\"\", \n",
    "        \"»\": \"\\\"\", \n",
    "        \"{{(R)}}\": \"\",\n",
    "        \"fig.\": \"figurativ:\",\n",
    "        \"{{Neutr.}}\": \"\",\n",
    "        \"{{trans.|:}}\": \"\",\n",
    "        \"\\x80\": \"\",\n",
    "        \"\\x84\": \"\",\n",
    "        \"\\x93\": \"\", \n",
    "        \"\\x96\": \"\",\n",
    "        \"&#8239;\": \" \",\n",
    "        \"&#91;sic&#93;\": \"[sic]\",\n",
    "        \"&#x202f;\": \" \",\n",
    "        \"´\": \"\\\"\", \n",
    "        \"®\": \"\",\n",
    "        \"→\": \"\",\n",
    "        \"<!--\": \"\",\n",
    "        \"</br>\": \" \",\n",
    "        \"<br />\": \" \",\n",
    "        \"<br/>\": \" \",\n",
    "        \"<br>\": \" \",\n",
    "        \"<nowiki>[</nowiki>\": \"\",\n",
    "        \"<nowiki>]</nowiki>\": \"\",\n",
    "        \"|sonst|\": \"|\",\n",
    "        \"□\": \"\",\n",
    "        \"vatd.\": \"veraltend\",\n",
    "        \"<nowiki/>\": \"\"\n",
    "    }\n",
    "    \n",
    "    def replace_k(k_text):\n",
    "        k_text = k_text.replace(\"{{K|\", \"\")\n",
    "        k_text = k_text.replace(\"}}\", \"\")\n",
    "        k_text = k_text.split(\"|\")\n",
    "        use_elements = []\n",
    "        for el in k_text:\n",
    "            el = el.strip()\n",
    "            if el in replacements_k:\n",
    "                el = replacements_k[el]\n",
    "            if \"=\" in el or \"\" == el:\n",
    "                continue\n",
    "            use_elements.append(el)\n",
    "        if len(use_elements) > 0:\n",
    "            return \", \".join(use_elements) + \":\"\n",
    "        else:\n",
    "            return \"\"\n",
    "    \n",
    "    for key, value in replacements.items():\n",
    "        input_text = input_text.replace(key, value)\n",
    "\n",
    "    input_text = remove_tags(input_text, \"nowiki\")\n",
    "\n",
    "    def keyword_last(input_text, keyword):\n",
    "        return re.sub(r\"{{\" + keyword + \"\\|.*?}}\", lambda u: u.group(0).replace(\"{{\" + keyword + \"|\", \"\").replace(\"}}\", \"\").split(\"|\")[-1], input_text).strip()\n",
    "\n",
    "    def keyword_delete(input_text, keyword):\n",
    "        return re.sub(r\"{{\" + keyword + \".*?}}\", \"\", input_text).strip()\n",
    "    \n",
    "    input_text = re.sub(r\"\\[\\[Datei:.*?]]\", \"\", input_text)\n",
    "\n",
    "    # filter [[]] and [[|]]\n",
    "    input_text = re.sub(r'\\[\\[([^\\|\\]]+)\\|([^\\|\\]]+)\\]\\]', lambda u: u.group(2), input_text)\n",
    "\n",
    "    # filter {{K|}}    \n",
    "    input_text = re.sub(r\"{{K\\|.*?}}\", lambda u: replace_k(u.group(0)), input_text).strip()\n",
    "\n",
    "    # filter []\n",
    "    input_text = input_text.replace(\"[...]\", \"!!REPLACEMENTPLACEHOLDER!!\")\n",
    "    input_text = re.sub(r'\\[([^\\|\\]]+)\\]', r'\\1', input_text)\n",
    "    input_text = input_text.replace(\"!!REPLACEMENTPLACEHOLDER!!\", \"[...]\")\n",
    "    # delete completely\n",
    "\n",
    "    input_text = keyword_last(input_text, \"Üt\")\n",
    "    input_text = keyword_last(input_text, \"Ü\")\n",
    "    input_text = keyword_last(input_text, \"Farbe\")\n",
    "    input_text = keyword_last(input_text, \"L\")\n",
    "\n",
    "    input_text = keyword_delete(input_text, \"Bibel\")\n",
    "    input_text = keyword_delete(input_text, \"Anker\")\n",
    "    input_text = keyword_delete(input_text, \"Audio\")\n",
    "\n",
    "    input_text = keyword_delete(input_text, \"Internetquelle\")\n",
    "    input_text = keyword_last(input_text, \"Polytonisch\")\n",
    "    input_text = keyword_delete(input_text, \"QS Bedeutung(en)?\")\n",
    "    input_text = keyword_delete(input_text, \"Literatur \")\n",
    "    input_text = keyword_delete(input_text, \"Literatur\")\n",
    "\n",
    "    input_text = keyword_delete(input_text, \"Ref-dejure\")\n",
    "    input_text = keyword_delete(input_text, \"Wikipedia\")\n",
    "    input_text = keyword_delete(input_text, \"Wikisource\")\n",
    "    input_text = keyword_delete(input_text, \"W\\|\")\n",
    "    input_text = keyword_delete(input_text, \"w\\|\")\n",
    "\n",
    "    # take last entry only\n",
    "    input_text = keyword_last(input_text, \"Hintergrundfarbe\")\n",
    "    input_text = keyword_last(input_text, \"Lautschrift\")\n",
    "    input_text = keyword_last(input_text, \"WP\")\n",
    "    \n",
    "    if \"{{\" in input_text:\n",
    "        debug_me.append(input_text)\n",
    "    \n",
    "    input_text = re.sub(r'{{([^|]*?)[,;:]*?\\|*?([:,;. ]*?)}}', r'\\1\\2', input_text)\n",
    "    input_text = re.sub(r'{{[,;:]*?\\|*?.*?}}', '', input_text)\n",
    "    input_text = re.sub(\"{{}}\", \"\", input_text)\n",
    "    input_text = re.sub(\".*?}}\", \"\", input_text)\n",
    "    input_text = input_text.replace(\",:\", \":\")\n",
    "    \n",
    "    \n",
    "    return re.sub(\"<ref>$\", \"\", input_text.replace( \"[[\", \"\").replace(\"]]\", \"\")).replace(\"-->\", \"\").replace(\"<--\", \"\").replace(\"<!--\", \"\").replace(\"()\", \"\").replace(\"ͤ\", \"\").strip(\", .:\")\n",
    "\n",
    "\n",
    "\n",
    "@classmethod\n",
    "def _sanitize_context(cls, input_text: str) -> str:\n",
    "    input_text = input_text.removesuffix(\"\\n}}\")\n",
    "    input_text = cls._sanitize_spaces(input_text)\n",
    "    \n",
    "\n",
    "    # Substitute the matched characters with an empty string\n",
    "    return global_sanitize(input_text)\n",
    "\n",
    "@classmethod\n",
    "def _sanitize_word(cls, input_text: str) -> str:\n",
    "    input_text = input_text.removesuffix(\"\\n}}\")\n",
    "    input_text = cls._sanitize_spaces(input_text)\n",
    "\n",
    "    return global_sanitize(input_text)\n",
    "\n",
    "@classmethod\n",
    "def _sanitize_gt(cls, input_text: str) -> str:\n",
    "    input_text = input_text.removesuffix(\"\\n}}\")\n",
    "    input_text = cls._sanitize_spaces(input_text)\n",
    "\n",
    "    return global_sanitize(input_text)\n",
    "\n",
    "@classmethod\n",
    "def _preprocessing(cls, examples):\n",
    "    from src.prompting import prompt_pattern\n",
    "    context_word = [cls._sanitize_word(w) for w in examples['context_word']]\n",
    "    title = [cls._sanitize_word(w) for w in examples['title']]\n",
    "    context_sentence = [cls._sanitize_context(w) for w in examples['context_sentence']]\n",
    "    gt = [cls._sanitize_gt(w) for w in examples['gt']]\n",
    "    input_texts = [prompt_pattern(c, w, pattern=cls.prompt_pattern) for c, w in zip(context_sentence, context_word)]\n",
    "    inputs = cls.tokenizer(input_texts, max_length=512, truncation=True)\n",
    "    inputs[\"labels\"] = cls.tokenizer(text_target=gt, max_length=128, truncation=True)[\"input_ids\"]\n",
    "    inputs[\"prompt\"] = input_texts # cls.tokenizer.batch_decode(inputs[\"input_ids\"])\n",
    "    inputs[\"title\"] = title\n",
    "    inputs[\"context_word\"] = context_word\n",
    "    inputs[\"context_sentence\"] = context_sentence\n",
    "    inputs[\"gt\"] = gt # cls.tokenizer.batch_decode(inputs[\"labels\"])\n",
    "\n",
    "    return inputs\n",
    "\n",
    "\n",
    "DefinitionDataset._sanitize_context = _sanitize_context\n",
    "DefinitionDataset._sanitize_word = _sanitize_word\n",
    "DefinitionDataset._sanitize_gt = _sanitize_gt\n",
    "DefinitionDataset._preprocessing = _preprocessing\n",
    "\n",
    "DefinitionDataset.tokenizer = tokenizer\n",
    "dataset_train, dataset_val = DefinitionDataset._data_loading(True, 42, -1, -1)\n",
    "set_train, set_val = DefinitionDataset._prepare_data(dataset_train, cache=False), DefinitionDataset._prepare_data(dataset_val, cache=False)"
   ],
   "id": "412804b4e52b37eb",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/288148 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b5cf64758b61445db9769871cc88f9c9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/35664 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "70ae3bb69c194cafb0ccaee8f3c1aea4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T15:18:54.652358Z",
     "start_time": "2024-07-17T15:18:54.649432Z"
    }
   },
   "cell_type": "code",
   "source": "global_sanitize(\"{{trans.|:}} mit – insbesondere [[maschinell]] [[erzeugt]]em – [[Schnee]] [[bedecken]]\")",
   "id": "717721002d3a8da6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mit - insbesondere maschinell erzeugtem - Schnee bedecken'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-24T08:51:12.677643Z",
     "start_time": "2024-07-24T08:49:27.180740Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "print(\"RUNNING\")\n",
    "search_regex = r'[^\\p{L}0-9 :\"().,;!?\\-/\\'&%=$§@°\\*€†≈~¥\\+#]'\n",
    "filter_regex = r'<math>'\n",
    "\n",
    "def contains_special(input_string):\n",
    "    input_string = input_string.replace(\"[...]\", \"!!REPLACEMENTPLACEHOLDER!!\")\n",
    "    regex = re.compile(search_regex)\n",
    "    search_result = regex.search(input_string)\n",
    "    # input_string.replace(\"!!REPLACEMENTPLACEHOLDER!!\", \"[...]\")\n",
    "\n",
    "    # Search the input string for any matches\n",
    "    if search_result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def contains_math(input_string):\n",
    "    regex = re.compile(filter_regex)\n",
    "    search_result = regex.search(input_string)\n",
    "\n",
    "    # Search the input string for any matches\n",
    "    if search_result:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "\n",
    "special_idx = []\n",
    "no_special_idx = []\n",
    "new_no_special_idx = []\n",
    "\n",
    "math_idx = []\n",
    "no_math_idx = []\n",
    "\n",
    "for x, datapoint in tqdm(enumerate(set_train)):\n",
    "    if contains_special(datapoint['context_sentence']) or contains_special(datapoint['context_word']) or contains_special(datapoint['gt']):\n",
    "        special_idx += [x]\n",
    "        # print(f\"{i['title']}: {i['context_word']} in {i['context_sentence']}\\n{i['gt']}\")\n",
    "    else:\n",
    "        no_special_idx += [x]\n",
    "        if x in old_special_idx:\n",
    "            new_no_special_idx += [x]\n",
    "\n",
    "    if contains_math(datapoint['context_sentence']) or contains_math(datapoint['context_word']) or contains_math(datapoint['gt']):\n",
    "        math_idx += [x]\n",
    "        # print(f\"{i['title']}: {i['context_word']} in {i['context_sentence']}\\n{i['gt']}\")\n",
    "    else:\n",
    "        no_math_idx += [x]\n",
    "\n",
    "print(len(special_idx))\n",
    "print(len(math_idx))\n",
    "print(len(no_special_idx))\n",
    "old_special_idx = list(special_idx)\n",
    "df = pd.DataFrame.from_dict(set_train)\n",
    "df.drop(columns=['input_ids', 'attention_mask', 'labels'], inplace=True)\n",
    "special = df.iloc[special_idx].drop(index=math_idx)\n",
    "no_special = df.drop(index=set(special_idx + math_idx))\n",
    "new_no_special = df.iloc[new_no_special_idx]\n",
    "\n",
    "# TODO REMOVE MATH FROM DATASET!\n",
    "\n",
    "math = df.iloc[math_idx]\n",
    "no_math = df.drop(index=math_idx)\n",
    "\n",
    "pandasgui.show(special, no_special, new_no_special, math, no_math)"
   ],
   "id": "be3e97a107b50a23",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RUNNING\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bcea255fdfa64a62929a274a3cc65f65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "469\n",
      "0\n",
      "287553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_909483/1914664112.py:63: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x7836567a2440>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T13:28:14.876725Z",
     "start_time": "2024-07-15T13:28:14.874003Z"
    }
   },
   "cell_type": "code",
   "source": "DefinitionDataset._sanitize_spaces(dataset_train[71905]['context_sentence'])",
   "id": "96fdc64301f1cf72",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"„Basis für ''Sonnensegel'' ist der Strahlungsdruck des Lichts. Die Teilchen die unser ''Sonnensegel'' als Antrieb nutzt sind Lichtteilchen (Photonen).“<ref>[http://www.bernd-leitenberger.de/sonnensegel.shtml Sonnensegel]''www.bernd-leitenberger.de'', abgerufen am 15. Juli 2013</ref> [[Datei:Bat_roof.jpeg|thumb|[3] Das Dach mit Solarmodulen als ''Sonnensegel'']]\""
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 23
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T14:44:30.249446Z",
     "start_time": "2024-07-17T14:44:22.807062Z"
    }
   },
   "cell_type": "code",
   "source": [
    "problematic_els = []\n",
    "\n",
    "for i, el in enumerate(set_train):\n",
    "    if \".:\" in el['gt'] or \".,\" in el['gt'] or \".;\" in el['gt']:\n",
    "        problematic_els += [i]"
   ],
   "id": "c755dbbfac62297b",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T14:44:31.599647Z",
     "start_time": "2024-07-17T14:44:31.597145Z"
    }
   },
   "cell_type": "code",
   "source": "len(problematic_els)",
   "id": "50d34370b3f4f495",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2506"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T14:45:59.982302Z",
     "start_time": "2024-07-17T14:45:50.821873Z"
    }
   },
   "cell_type": "code",
   "source": [
    "df = pd.DataFrame.from_dict(set_train)\n",
    "df.drop(columns=['input_ids', 'attention_mask', 'labels'], inplace=True)\n",
    "pandasgui.show(df.iloc[problematic_els])"
   ],
   "id": "a3e85b6231915b6e",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "/tmp/ipykernel_1336890/485035752.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pandasgui.show(df.iloc[problematic_els])\n",
      "/tmp/ipykernel_1336890/485035752.py:3: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  pandasgui.show(df.iloc[problematic_els])\n",
      "/tmp/ipykernel_1336890/485035752.py:3: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_1336890/485035752.py:3: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_1336890/485035752.py:3: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n",
      "/tmp/ipykernel_1336890/485035752.py:3: FutureWarning:\n",
      "\n",
      "Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x74f76438e8c0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T14:20:31.421471Z",
     "start_time": "2024-07-11T14:20:31.419505Z"
    }
   },
   "cell_type": "code",
   "source": "idx_it = iter(range(len(special)))",
   "id": "42a66ef1eede308",
   "outputs": [],
   "execution_count": 67
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T22:48:44.336609Z",
     "start_time": "2024-07-11T22:48:44.333248Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def search_special(input_string):\n",
    "    input_string = input_string.replace(\"[...]\", \"!!REPLACEMENTPLACEHOLDER!!\")\n",
    "    regex = re.compile(search_regex)\n",
    "    search_result = regex.search(input_string)\n",
    "    input_string.replace(\"!!REPLACEMENTPLACEHOLDER!!\", \"[...]\")\n",
    "\n",
    "    # Search the input string for any matches\n",
    "    return search_result\n",
    "\n",
    "idx = next(idx_it)\n",
    "print(idx)\n",
    "print(search_special(special.iloc[idx]['context_sentence']))\n",
    "print(search_special(special.iloc[idx]['gt']))"
   ],
   "id": "ad23576f151c14e4",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "None\n",
      "<regex.Match object; span=(193, 251), match='{{QS Bedeutungen|beschreibt ein Substantiv kein Adjektiv}}'>\n"
     ]
    }
   ],
   "execution_count": 146
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T14:21:14.159128Z",
     "start_time": "2024-07-11T14:21:14.156303Z"
    }
   },
   "cell_type": "code",
   "source": [
    "search_special(special.iloc[idx]['context_sentence'])\n",
    "special.iloc[idx]['context_sentence']"
   ],
   "id": "6239985a334ee89f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"Wenn der Landes\\u200bwolfsbeauftragte ihn als Problemwolf einstuft, kann er geschossen werden.\"'"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 72
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T14:01:45.188425Z",
     "start_time": "2024-07-15T14:01:45.184587Z"
    }
   },
   "cell_type": "code",
   "source": [
    "found_matches = []\n",
    "relevant_sentences = []\n",
    "for _, i in special.iterrows():\n",
    "    regex = re.compile(search_regex)\n",
    "    if a := regex.search(i['context_sentence']):\n",
    "        found_matches.append(a.group(0))\n",
    "        relevant_sentences.append(i['context_sentence'])\n",
    "    if a := regex.search(i['gt']):\n",
    "        found_matches.append(a.group(0))\n",
    "        relevant_sentences.append(i['gt'])"
   ],
   "id": "515bf4f0169a1da5",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T14:01:45.739978Z",
     "start_time": "2024-07-15T14:01:45.737436Z"
    }
   },
   "cell_type": "code",
   "source": "set(found_matches)",
   "id": "1f49c53f54d06e0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T14:01:47.841624Z",
     "start_time": "2024-07-15T14:01:47.838864Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(found_matches)"
   ],
   "id": "2474c36fd641597a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter()"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-15T13:35:15.045630Z",
     "start_time": "2024-07-15T13:35:15.017280Z"
    }
   },
   "cell_type": "code",
   "source": "pandasgui.show(relevant_sentences)",
   "id": "ea0f813c754fd549",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PandasGUI INFO — pandasgui.gui — Opening PandasGUI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pandasgui.gui.PandasGui at 0x79ba782668c0>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 34
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\"(\\u200b|\\u200e|\\u2060|\\u200d|\\u200c)\"|\\x96': 1,\n",
    "         '\\x80': 1,\n",
    "         '\\x93': 1,\n",
    "         '\\xad': 1,\n",
    "         '\\ufeff': 1,\n",
    "         '\\x84': 1,}"
   ],
   "id": "1ff7514d7585c2c2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-11T13:59:44.493302Z",
     "start_time": "2024-07-11T13:59:44.490827Z"
    }
   },
   "cell_type": "code",
   "source": [
    "text = \"This is Test <!--, ''auch:'' [[erste]]/[[erster|-r]]/[[erstes|-s]], [[beste]]/[[bester|-r]]/[[bestes|-s]], [[extremste]]/[[extremste|-r]]/[[extremste|-s]]--> Wow!!! <!-- Test -->\"\n",
    "cleaned_text = re.sub(r'<!--.*?-->', '', text)\n",
    "\n",
    "print(cleaned_text)\n"
   ],
   "id": "4fdcc5531772f7d7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is Test  Wow!!! \n"
     ]
    }
   ],
   "execution_count": 43
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
