{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-07-16T21:44:02.348248Z",
     "start_time": "2024-07-16T21:43:50.895096Z"
    }
   },
   "source": [
    "from tqdm.auto import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "from evaluation import load_model\n",
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('google/mt5-base', legacy=False)\n",
    "from src.model_training.datasets.experiments_sanitize.complete_sanitization import DefinitionTestSet, DefaultTrainValSet\n",
    "\n",
    "dataset_test = DefinitionTestSet.create_dataset(tokenizer, shuffle=True, seed=42, subset_test=-1, cache=False)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jfeil/.pyenv/versions/3.10.12/envs/MasterThesis-NLP/lib/python3.10/site-packages/transformers/convert_slow_tokenizer.py:562: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Map:   0%|          | 0/12968 [00:00<?, ? examples/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "ec1e68aa66224a88a91831d981e576a5"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:57:59.199376Z",
     "start_time": "2024-07-16T21:57:48.050799Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import spacy\n",
    "nlp = spacy.load('de_dep_news_trf')\n",
    "from HanTa import HanoverTagger as ht\n",
    "\n",
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n",
    "\n",
    "\n",
    "wrong_pairs = []\n",
    "\n",
    "for title, context_word in tqdm(zip(dataset_test[\"title\"], dataset_test[\"context_word\"])):\n",
    "    if title == context_word:\n",
    "        continue\n",
    "    if title == \"\" or context_word == \"\":\n",
    "        wrong_pairs.append((title, context_word))\n",
    "        continue\n",
    "    if (a:=str(tagger.analyze(title)[0])) != (b:=str(tagger.analyze(context_word)[0])):\n",
    "        if title != b:\n",
    "            wrong_pairs.append((title,context_word))"
   ],
   "id": "471668562e29791d",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0it [00:00, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "9bd0fcc88c9c488e9bd58fec1d33021f"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:57:59.852440Z",
     "start_time": "2024-07-16T21:57:59.849752Z"
    }
   },
   "cell_type": "code",
   "source": "len(wrong_pairs)",
   "id": "aba84d3fb99411a6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "867"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:58:00.967231Z",
     "start_time": "2024-07-16T21:58:00.962498Z"
    }
   },
   "cell_type": "code",
   "source": "wrong_pairs[0:100]",
   "id": "9f6403d7306e0ba0",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('herzukommen', 'kamen'),\n",
       " ('Protokoll errichten', 'wurden'),\n",
       " ('Elementarereignis', 'Elementarereignisse'),\n",
       " ('Mola', 'Molakana'),\n",
       " ('zusammensacken', 'sackt'),\n",
       " ('Abkauf', 'Abkaufe'),\n",
       " ('Büchertisch', 'Büchertische'),\n",
       " ('ausgucken', 'guckte'),\n",
       " ('bruchlanden', 'bruchlandet'),\n",
       " ('zecken', 'gezeckt'),\n",
       " ('scheiteln', 'gescheitelt'),\n",
       " ('anfreunden', 'sich'),\n",
       " ('Walross', 'Walrosse'),\n",
       " ('aufheitern', 'heiterte'),\n",
       " ('jemanden auf den Arm nehmen', 'hat'),\n",
       " ('gesalzen', 'gesalzenste'),\n",
       " ('rülpsen', 'rülpste'),\n",
       " ('Rechtsgelehrter', 'Rechtsgelehrten'),\n",
       " ('fortwollen', 'wollte'),\n",
       " ('ausgucken', 'guckte'),\n",
       " ('revanchieren', 'sich'),\n",
       " ('Zeitwort', 'Zeit'),\n",
       " ('Punsch', 'Punſches'),\n",
       " ('akkordieren', 'akkordierten'),\n",
       " ('zusammenrotten', 'rotten'),\n",
       " ('Nebeneinkunft', 'Nebeneinkünfte'),\n",
       " ('Leute', 'ironisch'),\n",
       " ('katadrom', 'katadromer'),\n",
       " ('Feststoff', 'Natronlauge'),\n",
       " ('streamlinen', 'streamlinte'),\n",
       " ('nicht von gestern sein', 'sind'),\n",
       " ('bätzen', 'Bätzen'),\n",
       " ('Mikrofossil', 'Mikrofossilien'),\n",
       " ('unterdrücken', 'unterdrückte'),\n",
       " ('bodigen', 'bodigte'),\n",
       " ('Götzenbild', 'Götzenbildern'),\n",
       " ('Sonnenfleck', 'Sonnenflecken'),\n",
       " ('Sonnenfleck', 'Sonnenflecken'),\n",
       " ('Fußmarsch', 'Fußmärschen'),\n",
       " ('Somalia', 'Das'),\n",
       " ('streamlinen', 'Streamlinen'),\n",
       " ('anspießen', 'wurde'),\n",
       " ('Abbozzo', 'Abbozzi'),\n",
       " ('Gewinn', 'haben'),\n",
       " ('Energiesparmodus', 'nergiesparmodi'),\n",
       " ('Privatgeld', 'Privatgelder'),\n",
       " ('anfreunden', 'sich'),\n",
       " ('Ubychisch', 'Ubychischen'),\n",
       " ('absetzen', 'setzt'),\n",
       " ('aufgeben', 'gibt'),\n",
       " ('einbläuen', 'bläut'),\n",
       " ('Eberhards', 'Eberhardsens'),\n",
       " ('Tapa', 'Tapas'),\n",
       " ('bestiften', 'Bestiften'),\n",
       " ('glasieren', 'habe'),\n",
       " ('rausfliegen', 'flog'),\n",
       " ('Konfirmationskleid', 'Konfirmationskleidern'),\n",
       " ('Blutzeuge', 'Blutzeugen'),\n",
       " ('Punsch', 'Punsche'),\n",
       " ('Erythrozyt', 'Erythrozyten'),\n",
       " ('einkellern', 'Einkellern'),\n",
       " ('jemand hat einen Zahn drauf', 'hat'),\n",
       " ('zurückmüssen', 'mußten'),\n",
       " ('wiederverlangen', 'wiederverlangte'),\n",
       " ('Nekrophiler', 'Nekrophile'),\n",
       " ('jö', 'Jö'),\n",
       " ('schilpen', 'schilpten'),\n",
       " ('Sonnenfleck', 'Sonnenflecken'),\n",
       " ('kohlen', 'kohlst'),\n",
       " ('Startläuferin', 'Startläuferinnen'),\n",
       " ('grammatische Funktion', 'grammatische'),\n",
       " ('meinereiner', 'Meinereiner'),\n",
       " ('hellgrau', 'hellgrauen'),\n",
       " ('wiederverwerten', 'werden'),\n",
       " ('unterbinden', 'Unterbinden'),\n",
       " ('bodigen', 'bodigten'),\n",
       " ('Kunststoffschreibtisch', 'Kunststoffschreibtischen'),\n",
       " ('anbleien', 'habe'),\n",
       " ('Huri', 'Huris'),\n",
       " ('Erythrozyt', 'Erythrozyten'),\n",
       " ('schauern', 'schauerte'),\n",
       " ('fußballern', 'fussballern'),\n",
       " ('Ossuarium', 'Ossuarien'),\n",
       " ('umholzen', 'hatte'),\n",
       " ('Sonderbevollmächtigter', 'Sonderbevollmächtigten'),\n",
       " ('verneunfachen', 'verneunfachte'),\n",
       " ('Spielanlass', 'Spielanlässen'),\n",
       " ('Sachschaden', 'Sachschäden'),\n",
       " ('entziehen', 'sich'),\n",
       " ('Lotterielos', 'Lotterielosen'),\n",
       " ('wegloben', 'lobte'),\n",
       " ('Abfallsortieranlage', 'wwwrosenbauercom'),\n",
       " ('ausfressen', 'frisst'),\n",
       " ('prunken', 'prunkte'),\n",
       " ('Werbeblock', 'Werbeblöcke'),\n",
       " ('Todeslaut', 'Todeslaute'),\n",
       " ('herumstolzieren', 'herumstolzierte'),\n",
       " ('Ranke', 'Ranken'),\n",
       " ('rückdenken', 'rückzudenken'),\n",
       " ('umholzen', 'hat')]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:50:16.686910Z",
     "start_time": "2024-07-16T21:50:16.566733Z"
    }
   },
   "cell_type": "code",
   "source": "len(dataset_test[\"title\"])",
   "id": "499902aa4fe6d2f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12966"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:56:21.162829Z",
     "start_time": "2024-07-16T21:56:20.744280Z"
    }
   },
   "cell_type": "code",
   "source": "import gensim",
   "id": "7e552255aa8d89ec",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:57:27.920975Z",
     "start_time": "2024-07-16T21:57:24.926701Z"
    }
   },
   "cell_type": "code",
   "source": [
    "trained_model = gensim.models.KeyedVectors.load_word2vec_format(\"../german.model\", binary=True)\n",
    "# remove original vectors to free up memory\n",
    "trained_model.init_sims(replace=True)"
   ],
   "id": "3a70fc5d441c0997",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_818162/2629584517.py:3: DeprecationWarning: Call to deprecated `init_sims` (Use fill_norms() instead. See https://github.com/RaRe-Technologies/gensim/wiki/Migrating-from-Gensim-3.x-to-4).\n",
      "  trained_model.init_sims(replace=True)\n"
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:57:27.924417Z",
     "start_time": "2024-07-16T21:57:27.921856Z"
    }
   },
   "cell_type": "code",
   "source": "wrong_pairs[0:10]",
   "id": "476b96f0c336307a",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Hohlwelttheorie', 'Hohlwelttheorien'),\n",
       " ('herzukommen', 'kamen'),\n",
       " ('Protokoll errichten', 'wurden'),\n",
       " ('Elementarereignis', 'Elementarereignisse'),\n",
       " ('Mola', 'Molakana'),\n",
       " ('zusammensacken', 'sackt'),\n",
       " ('Abkauf', 'Abkaufe'),\n",
       " ('Büchertisch', 'Büchertische'),\n",
       " ('ausgucken', 'guckte'),\n",
       " ('bruchlanden', 'bruchlandet')]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T08:19:18.152015Z",
     "start_time": "2024-07-17T08:19:18.147469Z"
    }
   },
   "cell_type": "code",
   "source": [
    "scores = {}\n",
    "not_existing = []\n",
    "for pair in wrong_pairs:\n",
    "    if pair[0] not in trained_model or pair[1] not in trained_model:\n",
    "        not_existing.append(pair)\n",
    "        continue\n",
    "    scores[pair] = trained_model.similarity(*pair)"
   ],
   "id": "bf1b899deff835ae",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T08:19:47.615653Z",
     "start_time": "2024-07-17T08:19:47.610325Z"
    }
   },
   "cell_type": "code",
   "source": "scores",
   "id": "ac2e54420d782335",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('herzukommen', 'kamen'): 0.21078113,\n",
       " ('Walross', 'Walrosse'): 0.559744,\n",
       " ('Rechtsgelehrter', 'Rechtsgelehrten'): 0.5164976,\n",
       " ('Leute', 'ironisch'): 0.4003573,\n",
       " ('Feststoff', 'Natronlauge'): 0.7216188,\n",
       " ('Somalia', 'Das'): 0.18570444,\n",
       " ('absetzen', 'setzt'): 0.29549432,\n",
       " ('aufgeben', 'gibt'): 0.3369042,\n",
       " ('Tapa', 'Tapas'): 0.39488146,\n",
       " ('rausfliegen', 'flog'): 0.34729895,\n",
       " ('hellgrau', 'hellgrauen'): 0.7123754,\n",
       " ('Ranke', 'Ranken'): 0.34429857,\n",
       " ('Bazillus', 'Bazillen'): 0.6139989,\n",
       " ('Symposion', 'Symposien'): 0.50672805,\n",
       " ('Drive', 'Drives'): 0.574168,\n",
       " ('Sims', 'Simse'): 0.34383586,\n",
       " ('zugehen', 'Geht'): 0.46973208,\n",
       " ('wegkommen', 'komm'): 0.36368445,\n",
       " ('emporsteigen', 'stiegen'): 0.26267195,\n",
       " ('anstecken', 'steckte'): 0.3337894,\n",
       " ('vorstehen', 'steht'): 0.26066333,\n",
       " ('Fensterbank', 'Petersilie'): 0.45396656,\n",
       " ('unterziehen', 'ziehen'): 0.31653014,\n",
       " ('modellieren', 'Modellieren'): 0.54722416,\n",
       " ('Zyklus', 'Zyklen'): 0.5734326,\n",
       " ('zusammenziehen', 'zog'): 0.22634603,\n",
       " ('berechtigen', 'berechtigt'): 0.6813033,\n",
       " ('ausstrahlen', 'strahlte'): 0.5074892,\n",
       " ('anmieten', 'wurde'): 0.21729068,\n",
       " ('rausfliegen', 'fliegt'): 0.43107536,\n",
       " ('besonnen', 'besonnte'): 0.26542497,\n",
       " ('rausfliegen', 'fliegst'): 0.6278283,\n",
       " ('seitlich', 'Seitlich'): 0.5507419,\n",
       " ('Pick', 'Picks'): 0.43939456,\n",
       " ('dahinschmelzen', 'schmilzt'): 0.5230805,\n",
       " ('unterziehen', 'Zieh'): 0.14390485,\n",
       " ('Vorfall', 'Karfreitag'): 0.31893846,\n",
       " ('aufgeben', 'gab'): 0.33415505,\n",
       " ('dahinschmelzen', 'schmolz'): 0.46937066,\n",
       " ('vorspielen', 'spielt'): 0.4268152,\n",
       " ('zunehmen', 'nimmt'): 0.40883702,\n",
       " ('orientieren', 'orientierte'): 0.6341495,\n",
       " ('verbiegen', 'verbogene'): 0.41312203,\n",
       " ('antreten', 'trat'): 0.4976123,\n",
       " ('beigeben', 'Gib'): 0.3428957,\n",
       " ('backen', 'buk'): 0.47208616,\n",
       " ('Kolumbarium', 'Kolumbarien'): 0.5830293,\n",
       " ('Aviso', 'Avisos'): 0.6483062,\n",
       " ('Trema', 'Diastema'): 0.30825338,\n",
       " ('Derwisch', 'Derwische'): 0.5245346,\n",
       " ('hervorstehen', 'steht'): 0.17345431,\n",
       " ('kassieren', 'kassierten'): 0.6409346,\n",
       " ('Rate', 'Raten'): 0.5572222,\n",
       " ('abfallen', 'fallen'): 0.48260328,\n",
       " ('ausstrahlen', 'strahlt'): 0.59299564,\n",
       " ('nacharbeiten', 'arbeitet'): 0.3609095,\n",
       " ('krabbeln', 'gekrabbelt'): 0.6475979,\n",
       " ('Kelter', 'Keltern'): 0.53945285,\n",
       " ('Mola', 'sic'): 0.22734389,\n",
       " ('Okzitanisch', 'Okzitanischen'): 0.69141245,\n",
       " ('abheilen', 'heilt'): 0.5941559,\n",
       " ('Kalif', 'Kalifen'): 0.74298656,\n",
       " ('promoten', 'promotet'): 0.66459495,\n",
       " ('Glissando', 'Glissandi'): 0.7382737,\n",
       " ('schein', 'Schein'): 0.37083882,\n",
       " ('versanden', 'versandete'): 0.5759713,\n",
       " ('zunehmen', 'nahm'): 0.28195325,\n",
       " ('Teuerungsrate', 'Teuerungsraten'): 0.71780026,\n",
       " ('aufeinanderprallen', 'prallen'): 0.52427363,\n",
       " ('zugehen', 'geht'): 0.46876562,\n",
       " ('end', 'nd'): 0.23132892,\n",
       " ('salzen', 'gesalzen'): 0.7786442,\n",
       " ('aufgeben', 'gebe'): 0.31139487,\n",
       " ('wegkommen', 'komme'): 0.47455618,\n",
       " ('umgehen', 'gehen'): 0.43567163,\n",
       " ('Ziegenfleisch', 'Ziegen'): 0.4677423,\n",
       " ('Boje', 'Bojen'): 0.60319823,\n",
       " ('digitalisieren', 'digitalisierten'): 0.5638999,\n",
       " ('antreten', 'tritt'): 0.6009625,\n",
       " ('heim', 'Heim'): 0.41711432,\n",
       " ('Alkoholkonsum', 'Alkohol'): 0.721469,\n",
       " ('Auster', 'Austern'): 0.47052172,\n",
       " ('absetzen', 'wurde'): 0.27749994,\n",
       " ('aufgeben', 'geben'): 0.44201118,\n",
       " ('zunehmen', 'zunehmendem'): 0.54546386,\n",
       " ('anmieten', 'mietet'): 0.6932882,\n",
       " ('entgegenbringen', 'bringe'): 0.47058868,\n",
       " ('Bahre', 'Bahren'): 0.38110977,\n",
       " ('promoten', 'promotete'): 0.61047804,\n",
       " ('abtrotzen', 'trotzte'): 0.4015523,\n",
       " ('umgehen', 'geht'): 0.38766903,\n",
       " ('vorspielen', 'Spiel'): 0.38900638,\n",
       " ('entlanggehen', 'gingen'): 0.25051,\n",
       " ('unterlegen', 'Leg'): 0.18261145,\n",
       " ('Lebenswirklichkeit', 'Tweet'): 0.20081334,\n",
       " ('backen', 'gebackene'): 0.6210866,\n",
       " ('antreten', 'traten'): 0.47647414,\n",
       " ('gebieten', 'gebot'): 0.5528651,\n",
       " ('herzukommen', 'kam'): 0.19382747,\n",
       " ('Zytostatikum', 'Zytostatika'): 0.7672032,\n",
       " ('umgehen', 'ging'): 0.27593967,\n",
       " ('Laboratorium', 'Laboratorien'): 0.54775435,\n",
       " ('vorspielen', 'spiel'): 0.45128363,\n",
       " ('achtgeben', 'Gib'): 0.4299699,\n",
       " ('Hauptzeuge', 'Hauptzeugen'): 0.67841244,\n",
       " ('umherlaufen', 'laufen'): 0.35617766,\n",
       " ('jazzig', 'jazziger'): 0.8047233,\n",
       " ('abheilen', 'heilen'): 0.5921867,\n",
       " ('zunehmen', 'zunehmender'): 0.630133,\n",
       " ('hurra', 'Hurra'): 0.6049293,\n",
       " ('innert', 'Innert'): 0.6415977,\n",
       " ('zerschneiden', 'zerschnitt'): 0.49806744,\n",
       " ('qualifizieren', 'qualifizierten'): 0.73275286,\n",
       " ('abheilen', 'heilte'): 0.48156708,\n",
       " ('Bete', 'Beten'): 0.43916446,\n",
       " ('aufgeben', 'Verneinung'): 0.17605679,\n",
       " ('Katechet', 'Katecheten'): 0.53224266}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:40:51.263823Z",
     "start_time": "2024-07-16T21:40:51.261044Z"
    }
   },
   "cell_type": "code",
   "source": "trained_model.similarity('Spielverlust', 'Spielverluste')",
   "id": "a9b91a258929a686",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.99999994"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:50:24.806913Z",
     "start_time": "2024-07-16T21:50:23.405358Z"
    }
   },
   "cell_type": "code",
   "source": "nlp = spacy.load('de_dep_news_trf')",
   "id": "636efee294b072df",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:50:38.593801Z",
     "start_time": "2024-07-16T21:50:38.575350Z"
    }
   },
   "cell_type": "code",
   "source": "nlp('Spielverlust')",
   "id": "f317e46b7f2ee17c",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Spielverlust"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:52:00.662177Z",
     "start_time": "2024-07-16T21:52:00.597813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from HanTa import HanoverTagger as ht\n",
    "\n",
    "tagger = ht.HanoverTagger('morphmodel_ger.pgz')\n"
   ],
   "id": "a94a2164f7f77434",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-16T21:52:20.264017Z",
     "start_time": "2024-07-16T21:52:20.260097Z"
    }
   },
   "cell_type": "code",
   "source": "print(tagger.analyze('Spielverluste')[0])",
   "id": "cacea612cd91a68e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spielverlust\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T08:15:53.939873Z",
     "start_time": "2024-07-17T08:15:53.937074Z"
    }
   },
   "cell_type": "code",
   "source": "'Hohlwelttheorie' in trained_model",
   "id": "f209bec7e50fd985",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:10:04.377590Z",
     "start_time": "2024-07-17T09:10:03.938891Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "\n",
    "# Load the BERT model and tokenizer\n",
    "bert_model = BertModel.from_pretrained('google-bert/bert-base-german-uncased')\n",
    "bert_tokenizer = BertTokenizer.from_pretrained('google-bert/bert-base-german-uncased')\n",
    "# bert_model.cuda()\n",
    "# Tokenize the input words\n",
    "word1 = \"test\"\n",
    "word2 = \"hohlwelttheorie\"\n",
    "\n",
    "def get_embedding(word):\n",
    "    # Tokenize the input word\n",
    "    inputs = bert_tokenizer(word, return_tensors='pt')\n",
    "    \n",
    "    # Get the outputs from BERT\n",
    "    with torch.no_grad():\n",
    "        outputs = bert_model(**inputs)\n",
    "    \n",
    "    # The outputs are of shape (batch_size, sequence_length, hidden_size)\n",
    "    # We need the embeddings of the input token(s)\n",
    "    embeddings = outputs.last_hidden_state\n",
    "    \n",
    "    # If the word is split into multiple tokens, we take the mean of their embeddings\n",
    "    # Otherwise, we take the embedding of the single token\n",
    "    word_embedding = embeddings.mean(dim=1).squeeze()\n",
    "\n",
    "    return word_embedding\n",
    "# Get the first and second word embeddings\n",
    "word1_embedding = get_embedding(word1)\n",
    "word2_embedding = get_embedding(word2)\n",
    "\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Function to calculate cosine similarity\n",
    "def cosine_similarity(embedding1, embedding2):\n",
    "    return F.cosine_similarity(embedding1.unsqueeze(0), embedding2.unsqueeze(0)).item()\n",
    "\n",
    "# Calculate the cosine similarity between the two words\n",
    "similarity = cosine_similarity(word1_embedding, word2_embedding)\n",
    "\n",
    "print(similarity)\n",
    "# tensor([0.9665, 0.7953, 0.9809], grad_fn=<SumBackward1>)"
   ],
   "id": "315fbfed5ba81f02",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7517393231391907\n"
     ]
    }
   ],
   "execution_count": 109
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:02:50.363824Z",
     "start_time": "2024-07-17T09:02:50.360898Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cosine_similarity(word1_embedding, word2_embedding)",
   "id": "9df0f95370bd7ebc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7517])"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 99
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:20:45.905527Z",
     "start_time": "2024-07-17T09:20:23.478897Z"
    }
   },
   "cell_type": "code",
   "source": [
    "similarity_scores = {}\n",
    "\n",
    "bad_pairs = {}\n",
    "good_pairs = {}\n",
    "\n",
    "for pair in tqdm(wrong_pairs):\n",
    "    word1_embedding = get_embedding(pair[0])\n",
    "    word2_embedding = get_embedding(pair[1])\n",
    "    \n",
    "    # Calculate the cosine similarity between the two words\n",
    "    similarity = cosine_similarity(word1_embedding, word2_embedding)\n",
    "    similarity_scores[pair] = similarity\n",
    "    if similarity < 0.75:\n",
    "        bad_pairs[pair] = similarity\n",
    "    else:\n",
    "        good_pairs[pair] = similarity\n"
   ],
   "id": "c2aa8fe1e797eccd",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "  0%|          | 0/867 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34a51bab822f4d128aa724cd18077076"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 122
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:14:43.875227Z",
     "start_time": "2024-07-17T09:14:43.870529Z"
    }
   },
   "cell_type": "code",
   "source": "bad_pairs",
   "id": "8f0f2928db87cc0f",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{('anfreunden', 'sich'): 0.6428645849227905,\n",
       " ('jemanden auf den Arm nehmen', 'hat'): 0.5350866913795471,\n",
       " ('revanchieren', 'sich'): 0.6730716228485107,\n",
       " ('nicht von gestern sein', 'sind'): 0.591154932975769,\n",
       " ('Somalia', 'Das'): 0.6057213544845581,\n",
       " ('anspießen', 'wurde'): 0.5769628882408142,\n",
       " ('Gewinn', 'haben'): 0.6792787909507751,\n",
       " ('glasieren', 'habe'): 0.6123042106628418,\n",
       " ('wiederverwerten', 'werden'): 0.6857559680938721,\n",
       " ('umholzen', 'hatte'): 0.698523759841919,\n",
       " ('wegloben', 'lobte'): 0.6728106737136841,\n",
       " ('Abfallsortieranlage', 'wwwrosenbauercom'): 0.690182089805603,\n",
       " ('weitmaschig', 'weitmaſchige'): 0.6720466017723083,\n",
       " ('ausbüxen', 'sind'): 0.5914334654808044,\n",
       " ('fortgießen', 'fortgegoſſen'): 0.6367546319961548,\n",
       " ('mithelfen', 'hatte'): 0.6454353332519531,\n",
       " ('in der Luft liegen', 'lag'): 0.6879861950874329,\n",
       " ('gute Miene zum bösen Spiel machen', 'macht'): 0.6883102655410767,\n",
       " ('emporsteigen', 'stiegen'): 0.6665600538253784,\n",
       " ('anstecken', 'steckte'): 0.6426550149917603,\n",
       " ('vorstehen', 'steht'): 0.6113495230674744,\n",
       " ('Fensterbank', 'Petersilie'): 0.5670462250709534,\n",
       " ('anhungern', 'sich'): 0.6874467730522156,\n",
       " ('inlinen', 'sind'): 0.6952821016311646,\n",
       " ('aufeinanderprallen', 'sind'): 0.6448638439178467,\n",
       " ('dahinten', 'Dahinten'): 0.6978623270988464,\n",
       " ('ausstrahlen', 'strahlte'): 0.6181889176368713,\n",
       " ('anmieten', 'wurde'): 0.633405864238739,\n",
       " ('wegloben', 'wurde'): 0.6476395130157471,\n",
       " ('anspießen', 'hat'): 0.643707811832428,\n",
       " ('zurückwinken', 'Wink'): 0.6995748281478882,\n",
       " ('etwas an den Haaren herbeiziehen', 'ziehſt'): 0.6129496693611145,\n",
       " ('unterziehen', 'Zieh'): 0.6556872725486755,\n",
       " ('Vorfall', 'Karfreitag'): 0.5439755916595459,\n",
       " ('nahestehen', 'hatte'): 0.6842654943466187,\n",
       " ('auspflügen', 'werden'): 0.6207314133644104,\n",
       " ('ausgucken', 'sich'): 0.6142183542251587,\n",
       " ('neronisch', 'neroniſchen'): 0.6461179852485657,\n",
       " ('verstänkern', 'hatte'): 0.6735925078392029,\n",
       " ('vorspielen', 'spielt'): 0.6841573715209961,\n",
       " ('taxieren', 'hatte'): 0.660468339920044,\n",
       " ('anstecken', 'anzuſtecken'): 0.5588667392730713,\n",
       " ('fei', 'Erzgebirgisch'): 0.6150433421134949,\n",
       " ('nicht von gestern sein', 'biſt'): 0.6570695042610168,\n",
       " ('beigeben', 'Gib'): 0.6374640464782715,\n",
       " ('backen', 'buk'): 0.6099863052368164,\n",
       " ('verblättern', 'sich'): 0.6859235167503357,\n",
       " ('löhnen', 'gelöhnt'): 0.6654351949691772,\n",
       " ('dahinsterben', 'waren'): 0.6445947289466858,\n",
       " ('sich etwas durch die Lappen gehen lassen', 'sich'): 0.6240451335906982,\n",
       " ('backen', 'bäckt'): 0.6319013237953186,\n",
       " ('paffen', 'gepafft'): 0.679878294467926,\n",
       " ('ausstrahlen', 'strahlt'): 0.6820662021636963,\n",
       " ('aufknoten', 'aufgeknotet'): 0.6984767913818359,\n",
       " ('in der Luft liegen', 'Sensation'): 0.6540961265563965,\n",
       " ('Mola', 'sic'): 0.6638301610946655,\n",
       " ('ausgucken', 'hatte'): 0.6122303605079651,\n",
       " ('jemanden auf den Arm nehmen', 'mich'): 0.5710533261299133,\n",
       " ('Spaniolisch', 'Aschkenasim'): 0.6510409116744995,\n",
       " ('sauen', 'gesaut'): 0.6860902905464172,\n",
       " ('ausgucken', 'hat'): 0.6137611865997314,\n",
       " ('herausrupfen', 'wurden'): 0.6831887364387512,\n",
       " ('erwecken', 'hat'): 0.6965510845184326,\n",
       " ('weiterbeschäftigen', 'beschäftigt'): 0.6845031976699829,\n",
       " ('scheckiglachen', 'sich'): 0.6653329730033875,\n",
       " ('vollkrümeln', 'mich'): 0.6509233713150024,\n",
       " ('Dativus sympathicus', ''): 0.5609222054481506,\n",
       " ('abplacken', 'hat'): 0.6579524874687195,\n",
       " ('jemandem etwas mit gleicher Münze heimzahlen', 'Das'): 0.6372824311256409,\n",
       " ('auseinandertreiben', 'trieb'): 0.6481885313987732,\n",
       " ('Uganda', 'das'): 0.6445894837379456,\n",
       " ('ansiedeln', 'sich'): 0.6390103101730347,\n",
       " ('Außenwirkung', 'Starlet'): 0.6515377759933472,\n",
       " ('absetzen', 'wurde'): 0.6228777170181274,\n",
       " ('stummschalten', 'schalten'): 0.6893230676651001,\n",
       " ('umhingehen', 'geh'): 0.6829922795295715,\n",
       " ('zusammenrücken', 'rückten'): 0.6887451410293579,\n",
       " ('kaputtmachen', 'mich'): 0.6731139421463013,\n",
       " ('fei', 'Schwäbisch'): 0.6786542534828186,\n",
       " ('schwägern', 'geschwägert'): 0.6108342409133911,\n",
       " ('wegpacken', 'Pack'): 0.6566866636276245,\n",
       " ('schmal', 'schmäleren'): 0.6770029067993164,\n",
       " ('schwerfallen', 'ist'): 0.6258045434951782,\n",
       " ('vorspielen', 'Spiel'): 0.6411044597625732,\n",
       " ('touren', 'sind'): 0.6958408951759338,\n",
       " ('gute Miene zum bösen Spiel machen', 'haben'): 0.6728854775428772,\n",
       " ('schlecken', 'geschleckt'): 0.6914629936218262,\n",
       " ('fei', 'Fränkisch'): 0.6060917973518372,\n",
       " ('veranlassen', 'Veranlassen'): 0.6816866993904114,\n",
       " ('anstecken', 'hat'): 0.5726669430732727,\n",
       " ('kurieren', 'kurier'): 0.6784231662750244,\n",
       " ('Lebenswirklichkeit', 'Tweet'): 0.6695374846458435,\n",
       " ('fei', 'Vogtländisch'): 0.68006432056427,\n",
       " ('anorganisch', 't'): 0.6506869792938232,\n",
       " ('absetzen', 'hat'): 0.6596226692199707,\n",
       " ('dahinsterben', 'starb'): 0.6651188135147095,\n",
       " ('Oberkapelle', 'wwwlanguedocroussillonde'): 0.6047981977462769,\n",
       " ('anzischen', 'habe'): 0.6926746368408203,\n",
       " ('einwiegen', 'wog'): 0.68388831615448,\n",
       " ('vernadern', 'wurde'): 0.6863529086112976,\n",
       " ('jemanden durch den Wolf drehen', 'durch'): 0.6569319367408752,\n",
       " ('umhingehen', 'ummigehst'): 0.6867694854736328,\n",
       " ('erfreuen', 'sich'): 0.6358467936515808,\n",
       " ('vorspielen', 'spiel'): 0.6791455745697021,\n",
       " ('zerschneiden', 'sich'): 0.6077125668525696,\n",
       " ('abheilen', 'ist'): 0.5336767435073853,\n",
       " ('ein Händchen für etwas haben', 'hast'): 0.5541232228279114,\n",
       " ('zurückschieben', 'schob'): 0.6840953230857849,\n",
       " ('Grußkarte', 'selbstgemachten'): 0.6333351731300354,\n",
       " ('Protokoll errichten', 'wurde'): 0.6565129160881042,\n",
       " ('abhersagen', 'owasong'): 0.653951108455658}"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 118
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:21:41.860021Z",
     "start_time": "2024-07-17T09:21:41.857434Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for k, v in good_pairs.items():\n",
    "    if v < 0.8:\n",
    "        print(k)"
   ],
   "id": "4f5accc573aa8912",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('herzukommen', 'kamen')\n",
      "('zusammensacken', 'sackt')\n",
      "('ausgucken', 'guckte')\n",
      "('zecken', 'gezeckt')\n",
      "('aufheitern', 'heiterte')\n",
      "('fortwollen', 'wollte')\n",
      "('rausfliegen', 'flog')\n",
      "('zurückmüssen', 'mußten')\n",
      "('ausfressen', 'frisst')\n",
      "('kohlen', 'kohlte')\n",
      "('zugehen', 'Geht')\n",
      "('herausrupfen', 'haben')\n",
      "('nummerisch', 'Nummerisch')\n",
      "('weit', 'weiter')\n",
      "('ankotzen', 'kotzt')\n",
      "('Individualstil', 'Indivudualstil')\n",
      "('danebenliegen', 'lagen')\n",
      "('ribbeln', 'Ribbeln')\n",
      "('unterziehen', 'ziehen')\n",
      "('modellieren', 'Modellieren')\n",
      "('einfressen', 'frisst')\n",
      "('berechtigen', 'berechtigt')\n",
      "('rausfliegen', 'fliegt')\n",
      "('seitlich', 'Seitlich')\n",
      "('zerdrücken', 'zerdrückte')\n",
      "('aufpflanzen', 'aufgepflanzten')\n",
      "('behängen', 'werden')\n",
      "('aufgeben', 'gab')\n",
      "('Tübbing', 'tübbinge')\n",
      "('herumbekommen', 'hat')\n",
      "('zurückscheuen', 'scheut')\n",
      "('dahinschmelzen', 'schmolz')\n",
      "('Satinkleid', 'hauchzarten')\n",
      "('betriebsam', 'betriebsamste')\n",
      "('einbremsen', 'Einbremsen')\n",
      "('anschimmeln', 'schimmeln')\n",
      "('Trema', 'Diastema')\n",
      "('hervorstehen', 'steht')\n",
      "('bestiften', 'bestiftete')\n",
      "('Rate', 'Raten')\n",
      "('nacharbeiten', 'arbeitet')\n",
      "('abheilen', 'heilt')\n",
      "('Kalif', 'Kalifen')\n",
      "('rückblenden', 'rückgeblendet')\n",
      "('danebenliegen', 'lag')\n",
      "('zunehmen', 'nahm')\n",
      "('verpeilen', 'hab')\n",
      "('beweinen', 'beweinten')\n",
      "('Trägerin', 'übertragen')\n",
      "('arid', 'arider')\n",
      "('paffen', 'Paffen')\n",
      "('zugehen', 'geht')\n",
      "('end', 'nd')\n",
      "('wegkommen', 'komme')\n",
      "('aufpflanzen', 'pflanzt')\n",
      "('geschehen lassen', 'lasse')\n",
      "('danebenliegen', 'liegt')\n",
      "('unterbewusst', 'Unterbewusste')\n",
      "('ausbüxen', 'ausgebüxt')\n",
      "('elfenhaft', 'Elfengleich')\n",
      "('herhaben', 'hast')\n",
      "('aufknoten', 'knotet')\n",
      "('löhnen', 'löhnte')\n",
      "('zurückmüssen', 'müssen')\n",
      "('zerdrücken', 'zerdrück')\n",
      "('überschreiten', 'Überschreiten')\n",
      "('herhaben', 'hat')\n",
      "('zunehmen', 'zunehmendem')\n",
      "('anmieten', 'mietet')\n",
      "('zumailen', 'zuzumailen')\n",
      "('Boje', 'Nautictestcom')\n",
      "('hinuntergehen', 'gehen')\n",
      "('zum alten Eisen zählen', 'zählt')\n",
      "('entlanggehen', 'gingen')\n",
      "('zurückmüssen', 'zurückmuss')\n",
      "('bestiften', 'bestiftet')\n",
      "('Fürstentum', 'Fürstentümern')\n",
      "('anherrschen', 'herrschte')\n",
      "('aufheitern', 'heitert')\n",
      "('nachfordern', 'fordern')\n",
      "('backen', 'gebackene')\n",
      "('tachinieren', 'Tachiniere')\n",
      "('herzukommen', 'kam')\n",
      "('fortwollen', 'will')\n",
      "('Koalitionspartnerin', 'Koalisationspartnerin')\n",
      "('achtgeben', 'Gib')\n",
      "('dieselbe Sprache sprechen', 'sprechen')\n",
      "('umherlaufen', 'laufen')\n",
      "('plauschen', 'plauschst')\n",
      "('eine Nacht darüber schlafen', 'schlafe')\n",
      "('wissenschaftsbasiert', 'Wissenschaftsbasierte')\n",
      "('schlaumachen', 'schlaugemacht')\n",
      "('winkeln', 'gewinkelter')\n",
      "('übersommern', 'hatten')\n",
      "('Wachsvotiv', 'wwwaugsburgerallgemeinede')\n",
      "('abheilen', 'heilte')\n",
      "('auf die Kacke hauen', 'hauten')\n",
      "('in der Patsche sitzen', 'saß')\n"
     ]
    }
   ],
   "execution_count": 124
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:20:45.908640Z",
     "start_time": "2024-07-17T09:20:45.906538Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(f\"good pairs: {len(good_pairs)}\")\n",
    "print(f\"bad pairs: {len(bad_pairs)}\")"
   ],
   "id": "c4a11c5edad23ba7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good pairs: 516\n",
      "bad pairs: 183\n"
     ]
    }
   ],
   "execution_count": 123
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-17T09:08:45.904763Z",
     "start_time": "2024-07-17T09:08:45.901641Z"
    }
   },
   "cell_type": "code",
   "source": "torch.cosine_similarity(torch.tensor([[1.0]]), torch.tensor([[1.0]]))",
   "id": "6ff3019270f676ed",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 107
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
